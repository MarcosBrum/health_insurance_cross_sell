{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 0.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T17:32:00.374120Z",
     "start_time": "2021-02-26T17:31:59.459655Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scikitplot as skplt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit as sss\n",
    "\n",
    "from imblearn.ensemble import RUSBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 0.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T17:32:00.377976Z",
     "start_time": "2021-02-26T17:32:00.375373Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "home_path = \"/home/marcos/Documentos/comunidade_DS/pa004_health_insurance_cross_sell/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T17:32:00.404740Z",
     "start_time": "2021-02-26T17:32:00.380357Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_tree_train = pd.read_pickle(home_path + \"interim/df6_bal_tree_train.pkl\")\n",
    "\n",
    "df_tree_validation = pd.read_pickle(home_path + \"interim/df6_bal_tree_val.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 0.2 Separate train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T17:32:00.417124Z",
     "start_time": "2021-02-26T17:32:00.406498Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df7_train = df_tree_train.copy()\n",
    "\n",
    "df7_validation = df_tree_validation.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T17:32:00.430542Z",
     "start_time": "2021-02-26T17:32:00.418701Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vintage                 0\n",
       "annual_premium          0\n",
       "age                     0\n",
       "region_code             0\n",
       "policy_sales_channel    0\n",
       "vehicle_hist            0\n",
       "vehicle_damage          0\n",
       "previously_insured      0\n",
       "weight_ages             0\n",
       "id                      0\n",
       "response                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T17:32:00.441436Z",
     "start_time": "2021-02-26T17:32:00.432753Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vintage                 0\n",
       "annual_premium          0\n",
       "age                     0\n",
       "region_code             0\n",
       "policy_sales_channel    3\n",
       "vehicle_hist            0\n",
       "vehicle_damage          0\n",
       "previously_insured      0\n",
       "weight_ages             0\n",
       "id                      0\n",
       "response                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7_validation.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T17:32:00.448054Z",
     "start_time": "2021-02-26T17:32:00.443504Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76222, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I will drop the rows containing NAs from df7_validation. Since it contains over 76k rows, this must not make a big difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T17:32:00.465953Z",
     "start_time": "2021-02-26T17:32:00.450223Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vintage                 0\n",
       "annual_premium          0\n",
       "age                     0\n",
       "region_code             0\n",
       "policy_sales_channel    0\n",
       "vehicle_hist            0\n",
       "vehicle_damage          0\n",
       "previously_insured      0\n",
       "weight_ages             0\n",
       "id                      0\n",
       "response                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7_validation.dropna(axis=0, inplace=True)\n",
    "df7_validation.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T17:32:00.471539Z",
     "start_time": "2021-02-26T17:32:00.467968Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76219, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 0.3 Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T17:32:00.485997Z",
     "start_time": "2021-02-26T17:32:00.473049Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# precision_at_k\n",
    "def precision_at_k(data, k):\n",
    "    data = data.reset_index(drop=True)\n",
    "    data['n_samples'] = data.index + 1\n",
    "    data['precision_at_k'] = data['response'].cumsum() / data['n_samples']\n",
    "    return data.loc[k, 'precision_at_k']\n",
    "\n",
    "# recall_at_k\n",
    "def recall_at_k(data, k):\n",
    "    data = data.reset_index(drop=True)\n",
    "    data['recall_at_k'] = data['response'].cumsum() / data['response'].sum()\n",
    "    return data.loc[k, 'recall_at_k']\n",
    "\n",
    "# model predict\n",
    "def model_evaluate(model, model_name, data_train, data_val, k):\n",
    "    # separate X and Y data:\n",
    "    xtrain = data_train.drop(['id', 'response'], axis=1)\n",
    "    ytrain = data_train.response\n",
    "    xval = data_val.drop(['id', 'response'], axis=1)\n",
    "    yval = data_val.response\n",
    "    \n",
    "    # fit and predict_proba:\n",
    "    model.fit(xtrain, ytrain)\n",
    "    yhat_proba = model.predict_proba(xval)\n",
    "    \n",
    "    # transform yhat_proba to 1D-array\n",
    "    yhat_proba_1d = yhat_proba[:, 1].tolist()\n",
    "    \n",
    "    # include in dataframe\n",
    "    validation_data = data_val.copy()\n",
    "    validation_data['score'] = yhat_proba_1d\n",
    "    # sort\n",
    "    validation_data = validation_data.sort_values('score', ascending=False)\n",
    "    \n",
    "    # plot\n",
    "    skplt.metrics.plot_cumulative_gain(yval, yhat_proba);\n",
    "    \n",
    "    return pd.DataFrame({'Model name':model_name,\n",
    "                         'precision_at_k':precision_at_k(validation_data, k),\n",
    "                         'recall_at_k':recall_at_k(validation_data, k)}, index=[0])\n",
    "\n",
    "# model fit\n",
    "def model_fit(model, data):\n",
    "    # separate X and Y data:\n",
    "    xtrain = data.drop(['id', 'response'], axis=1)\n",
    "    ytrain = data.response\n",
    "    \n",
    "    # fit\n",
    "    model_fitted = model.fit(xtrain, ytrain)\n",
    "    \n",
    "    return model_fitted\n",
    "\n",
    "\n",
    "\n",
    "def cross_validation(model, model_name, training_data, k_top, kfolds, verbose=False):\n",
    "    # X separate X and Y data:\n",
    "    xtraining = training_data.drop(['response'], axis=1)\n",
    "    ytraining = training_data.response\n",
    "    \n",
    "    # cross-validation:\n",
    "    cv = sss(n_splits=kfolds)\n",
    "    prec_k_list = []\n",
    "    rec_k_list = []\n",
    "    for train_index, prim_val_index in cv.split(xtraining, ytraining):\n",
    "        X_training, X_prim_val = xtraining.iloc[train_index], xtraining.iloc[prim_val_index]\n",
    "        y_training, y_prim_val = ytraining.iloc[train_index], ytraining.iloc[prim_val_index]\n",
    "        \n",
    "        # remove id from training, and create new validation without id\n",
    "        X_training = X_training.drop(['id'], axis=1)\n",
    "        X_prim_val_no_id = X_prim_val.drop(['id'], axis=1)\n",
    "        \n",
    "        # fit and predict_proba\n",
    "        model.fit(X_training, y_training)\n",
    "        yhat_proba = model.predict_proba(X_prim_val_no_id)\n",
    "        \n",
    "        # transform yhat_proba to 1D-array\n",
    "        yhat_proba_1d = yhat_proba[:, 1].tolist()\n",
    "        \n",
    "        # reconstruct dataframe\n",
    "        prim_val = pd.concat([X_prim_val, y_prim_val], axis=1)\n",
    "        prim_val['score'] = yhat_proba_1d\n",
    "        prim_val = prim_val.sort_values('score', ascending=False)\n",
    "        \n",
    "        # evaluate accuracy and store in list\n",
    "        prec_k_list.append(precision_at_k(prim_val, k_top))\n",
    "        rec_k_list.append(recall_at_k(prim_val, k_top))\n",
    "    \n",
    "    #evaluate mean and std\n",
    "    prec_k_pred = np.round(np.mean(prec_k_list), 4).astype(str) + '+/-' + np.round(np.std(prec_k_list), 4).astype(str)\n",
    "    rec_k_pred = np.round(np.mean(rec_k_list), 4).astype(str) + '+/-' + np.round(np.std(rec_k_list), 4).astype(str)\n",
    "    \n",
    "    return pd.DataFrame({'Model name':model_name,\n",
    "                         'precision_at_k':prec_k_pred,\n",
    "                         'recall_at_k':rec_k_pred}, index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 7.0 Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 7.2 Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 7.2.3 RUS Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T17:34:18.918346Z",
     "start_time": "2021-02-26T17:32:00.487873Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>precision_at_k</th>\n",
       "      <th>recall_at_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Under Sampling Classifier</td>\n",
       "      <td>0.1868+/-0.0</td>\n",
       "      <td>0.9996+/-0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model name precision_at_k      recall_at_k\n",
       "0  Random Under Sampling Classifier   0.1868+/-0.0  0.9996+/-0.0001"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rus = RUSBoostClassifier(n_estimators=150, sampling_strategy=0.15, replacement=True, random_state=50)\n",
    "\n",
    "rus_cv_metrics = cross_validation(rus, \"Random Under Sampling Classifier\", df7_train, 20000, 5)\n",
    "\n",
    "rus_cv_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
